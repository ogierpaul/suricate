{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step - by - step Guide to finding potential matches\n",
    "1. Prepare the data\n",
    "2. Push the data to Elastic Search\n",
    "3. Create the first similarity matrix\n",
    "4. Use the Explorer to label representative sample of the data\n",
    "5. Do further scoring and add new features to the similarity matrix\n",
    "6. Train a machine learning model on the data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Prepare the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from suricate.data.companies import getleft, getright"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1444\n",
      "3177\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df_left_raw=getleft(nrows=None)\n",
    "df_right_raw = getright(nrows=None)\n",
    "print(df_left_raw.shape[0])\n",
    "print(df_right_raw.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def prepare_left(df):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    df2 = df\n",
    "    return df2\n",
    "\n",
    "def prepare_right(df):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    df2 = df\n",
    "    return df2\n",
    "\n",
    "df_left = prepare_left(df_left_raw)\n",
    "df_right = prepare_right(df_right_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Push the data to Elastic Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "import pandas as pd\n",
    "import time\n",
    "from suricate.dbconnectors.esconnector import index_with_es"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_right.set_index('ix', drop=True, inplace=True)\n",
    "esclient = elasticsearch.Elasticsearch()\n",
    "es_indice = 'df_right'\n",
    "if True:\n",
    "    try:\n",
    "        esclient.indices.delete(index=es_indice)\n",
    "    except:\n",
    "        pass\n",
    "    request_body = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 5\n",
    "        },\n",
    "\n",
    "        \"mappings\": {\n",
    "            \"_doc\": {\n",
    "                \"properties\": {\n",
    "                    \"ix\": {\"type\": \"keyword\"},\n",
    "                    \"name\": {\"type\": \"text\"},\n",
    "                    \"street\": {\"type\": \"text\"},\n",
    "                    \"city\": {\"type\": \"text\"},\n",
    "                    \"postalcode\": {\"type\": \"text\"},\n",
    "                    \"countrycode\": {\"type\": \"keyword\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    esclient.indices.create(index=es_indice, body=request_body)\n",
    "    index_with_es(client=esclient, df=df_right, index=es_indice, ixname=\"ix\", reset_index=True, doc_type='_doc')\n",
    "    time.sleep(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "catcount = esclient.count(index=es_indice)['count']\n",
    "assert catcount == df_right.shape[0]\n",
    "print(catcount)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create the first similarity matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from suricate.dbconnectors import EsConnector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scoreplan = {\n",
    "        'name': {\n",
    "            'type': 'FreeText'\n",
    "        },\n",
    "        'street': {\n",
    "            'type': 'FreeText'\n",
    "        },\n",
    "        'city': {\n",
    "            'type': 'FreeText'\n",
    "        },\n",
    "        'duns': {\n",
    "            'type': 'Exact'\n",
    "        },\n",
    "        'postalcode': {\n",
    "            'type': 'FreeText'\n",
    "        },\n",
    "        'countrycode': {\n",
    "            'type': 'Exact'\n",
    "        }\n",
    "    }\n",
    "escon = EsConnector(\n",
    "    client=esclient,\n",
    "    scoreplan=scoreplan,\n",
    "    index=\"right\",\n",
    "    explain=False,\n",
    "    size=10\n",
    ")\n",
    "df_left.set_index('ix', drop=True, inplace=True)\n",
    "Xtc = escon.fit_transform(X=df_left)\n",
    "ix = Xtc.index\n",
    "Xsbs = escon.getsbs(X=df_left, on_ix=ix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Explore the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from suricate.data.companies import getytrue\n",
    "from suricate.explore import Explorer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cheatsheet: load already determined labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = getytrue()\n",
    "print(y_true.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_questions = 100\n",
    "## Fit the cluster to non-supervized data\n",
    "exp = Explorer(n_simple=n_questions, n_hard=n_questions)\n",
    "exp.fit_cluster(X=Xtc[['es_score']])\n",
    "y_cluster = pd.Series(data=exp.pred_cluster(X=Xtc), index=Xtc.index, name='y_cluster')\n",
    "X_cluster = pd.DataFrame(y_cluster)\n",
    "X_cluster['avg_score'] = Xtc[['es_score']].mean(axis=1)\n",
    "X_cluster['y_true'] = y_true['y_true']\n",
    "X_cluster['ix']=Xtc['ix']\n",
    "X_cluster.reset_index(inplace=True, drop=False)\n",
    "X_cluster.set_index('ix', inplace=True)\n",
    "\n",
    "### Ask simple questions\n",
    "ix_simple = exp.ask_simple(X=Xtc)\n",
    "Sbs_simple = Xsbs.loc[ix_simple]\n",
    "y_simple = y_true.loc[ix_simple]['y_true']\n",
    "\n",
    "### Fit the cluser with supervized data\n",
    "exp.fit(X=Xtc, y=y_simple, fit_cluster=False)\n",
    "\n",
    "### Ask hard (pointed) questions\n",
    "ix_hard = exp.ask_hard(X=Xtc, y=y_simple)\n",
    "Sbs_hard = Xsbs.loc[ix_hard]\n",
    "y_hard = y_true.loc[ix_hard]['y_true']\n",
    "\n",
    "### Obtain the results of the labels\n",
    "y_questions = y_true.loc[ix_hard.union(ix_simple)]['y_true']\n",
    "X_questions = Xsbs.loc[y_questions.index].copy()\n",
    "X_questions['y_cluster'] = y_cluster\n",
    "X_questions['y_true'] = y_questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Further scoring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from suricate.sbsdftransformers import FuncSbsComparator\n",
    "from sklearn.pipeline import FeatureUnion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_sbs_score_list = [\n",
    "    ('name_fuzzy', FuncSbsComparator(on='name', comparator='fuzzy')),\n",
    "    ('street_fuzzy', FuncSbsComparator(on='street', comparator='fuzzy')),\n",
    "    ('name_token', FuncSbsComparator(on='name', comparator='token')),\n",
    "    ('street_token', FuncSbsComparator(on='street', comparator='token')),\n",
    "    ('city_fuzzy', FuncSbsComparator(on='city', comparator='fuzzy')),\n",
    "    ('postalcode_fuzzy', FuncSbsComparator(on='postalcode', comparator='fuzzy')),\n",
    "    ('postalcode_contains', FuncSbsComparator(on='postalcode', comparator='contains'))\n",
    "]\n",
    "scorer_sbs = FeatureUnion(transformer_list=_sbs_score_list)\n",
    "Xscores = pd.DataFrame(\n",
    "    data=scorer_sbs.fit_transform(X=Xsbs),\n",
    "    index=Xsbs.index,\n",
    "    columns=[c[0] for c in _sbs_score_list]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate with the scores from the previous step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xscores = pd.concat([Xtc[['es_scores']], Xscores], axis=1, ignore_index=False)\n",
    "print(Xscores.shape)\n",
    "print(Xscores.columns)\n",
    "Xscores.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Apply the machine-learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "again, for expediency, we will use the y_true already saved"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Make the pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('Impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('Scaler', Normalizer()),\n",
    "    ('PCA', PCA(n_components=4)),\n",
    "    ('Predictor', GradientBoostingClassifier(n_estimators=500))\n",
    "])\n",
    "scoring = ['precision', 'recall', 'accuracy']\n",
    "scores = cross_validate(estimator=pipe, X=Xscores, y=y_true, scoring=scoring, cv=0.5)\n",
    "for c in scoring:\n",
    "    print(pd.datetime.now(), ' | {} score: {}'.format(c, np.average(scores['test_'+c])))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}