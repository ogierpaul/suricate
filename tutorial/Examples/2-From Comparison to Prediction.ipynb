{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Comparison to Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter is about training a machine learning algorithm on the similarity scores calculated in the previous chapter, in order to predict if two records are essentially the same or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up of the score matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from suricate.data.companies import getXlr\n",
    "X_lr = getXlr(nrows=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>duns</th>\n",
       "      <th>countrycode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ea464e59-6a49-4424-af64-5a3eb67e502d</th>\n",
       "      <td>adf technologies championdoor adf technologies...</td>\n",
       "      <td>6 avenue jean monnet</td>\n",
       "      <td>colomiers</td>\n",
       "      <td>31770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8fa1b69-823b-4456-b13d-5235988514ae</th>\n",
       "      <td>fako</td>\n",
       "      <td>15 peutestrae</td>\n",
       "      <td>hamburg</td>\n",
       "      <td>20539</td>\n",
       "      <td>340213235.0</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77c66fd9-8215-4702-945b-92fd6958b535</th>\n",
       "      <td>rg gmbh</td>\n",
       "      <td>7 im meiel</td>\n",
       "      <td>waldenbuch</td>\n",
       "      <td>71111</td>\n",
       "      <td>319932075.0</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76e834db-6e0c-400a-8f51-98b2652fd479</th>\n",
       "      <td>datalis</td>\n",
       "      <td>8 avenue gutenberg</td>\n",
       "      <td>portet sur garonne</td>\n",
       "      <td>31125</td>\n",
       "      <td>260332779.0</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0e02feec-dbf0-4693-b7bf-0b4d01629baa</th>\n",
       "      <td>heider druck gmbh</td>\n",
       "      <td>102 116 paffrather str</td>\n",
       "      <td>bergisch gladbach</td>\n",
       "      <td>51465</td>\n",
       "      <td>323117283.0</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   name  ... countrycode\n",
       "ix                                                                                       ...            \n",
       "ea464e59-6a49-4424-af64-5a3eb67e502d  adf technologies championdoor adf technologies...  ...          FR\n",
       "d8fa1b69-823b-4456-b13d-5235988514ae                                               fako  ...          DE\n",
       "77c66fd9-8215-4702-945b-92fd6958b535                                            rg gmbh  ...          DE\n",
       "76e834db-6e0c-400a-8f51-98b2652fd479                                            datalis  ...          FR\n",
       "0e02feec-dbf0-4693-b7bf-0b4d01629baa                                  heider druck gmbh  ...          DE\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lr[0].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the score matrix\n",
    "We can pipeline and concatenate several comparators using standard scikit-learn operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suricate.lrdftransformers import FuzzyConnector, VectorizerConnector, ExactConnector\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [\n",
    "    ('name_vecword', VectorizerConnector(on='name', analyzer='word', ngram_range=(1,2))),\n",
    "    ('name_vecchar', VectorizerConnector(on='name', analyzer='char', ngram_range=(1,3))),\n",
    "    ('street_vecword', VectorizerConnector(on='street', analyzer='word', ngram_range=(1,2))),\n",
    "    ('street_vecchar', VectorizerConnector(on='street', analyzer='char', ngram_range=(1,3))),\n",
    "    ('city_vecchar', VectorizerConnector(on='city', analyzer='char', ngram_range=(1,3))),\n",
    "    ('postalcode_exact', ExactConnector(on='postalcode')),\n",
    "    ('duns_exact', ExactConnector(on='duns')),\n",
    "    ('countrycode_exact', ExactConnector(on='countrycode'))\n",
    "]\n",
    "transformer = FeatureUnion(scores)\n",
    "X_score = transformer.fit_transform(X_lr)\n",
    "X_score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.preprocessing import Normalizer as Scaler\n",
    "from sklearn.decomposition import PCA\n",
    "steps = [\n",
    "    ('scorer', transformer),\n",
    "    ('imputer', Imputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', Scaler()),\n",
    "    ('pca', PCA(n_components=3))\n",
    "]\n",
    "preprocessing_pipeline = Pipeline(steps)\n",
    "X_score_ready = preprocessing_pipeline.fit_transform(X=X_lr)\n",
    "print(X_score_ready.shape)\n",
    "# from seaborn import pairplot\n",
    "# %matplotlib inline\n",
    "# pairplot(pd.DataFrame(X_score_ready))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking representative questions\n",
    "#### By taking a sample of each cluster of pairs, we have a representative subset of the whole data set\n",
    "Since we have many possibles pairs (n_rows_left * n_rows_right), we must take a representative subset of all possible pairs in order to train the model. Based on the score matrix defined at the end of the preprocessing pipeline, we can do that using clustering. We cluster the pairs according to their similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from suricate.lrdftransformers import LrVisualHelper\n",
    "scores = FeatureUnion(transformer_list=[\n",
    "    ('y_cluster', KMeans(n_clusters=10)),\n",
    "    ('reduction1d', Pipeline(steps=[\n",
    "        ('reduction1d', PCA(n_components=1)),\n",
    "        ('quantile_scaler', QuantileTransformer())\n",
    "    ])),\n",
    "    ('sidebyside', LrVisualHelper())\n",
    "])\n",
    "y_cluster = KMeans(n_clusters=10).fit_predict(X_score_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "expected dimension of array: (10,1) or (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fbb2dbf51499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected dimension of array: ({a},1) or ({a},)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: expected dimension of array: (10,1) or (10,)"
     ]
    }
   ],
   "source": [
    "raise IndexError('expected dimension of array: ({a},1) or ({a},)'.format(a=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(data=y_cluster)\n",
    "questions = []\n",
    "for c in range(10):\n",
    "    questions+=y.loc[y==c].sample(5).index.tolist()\n",
    "questions = np.array(questions)\n",
    "type(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cluster.representative_questions(n_questions=10).sort_values(by=['similarity', 'cluster'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/paulogier/Google Drive/1-Work/results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
